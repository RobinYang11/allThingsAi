{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "data = torch.tensor(iris[iris.columns[0:4]].values).float()\n",
    "\n",
    "labels = torch.zeros(len(data),dtype=torch.long)\n",
    "\n",
    "labels[iris.species == 'versicolor'] = 1\n",
    "labels[iris.species == 'virginica'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11  12  13  14]\n",
      " [ 21  22  23  24]\n",
      " [ 31  32  33  34]\n",
      " [ 41  42  43  44]\n",
      " [ 51  52  53  54]\n",
      " [ 61  62  63  64]\n",
      " [ 71  72  73  74]\n",
      " [ 81  82  83  84]\n",
      " [ 91  92  93  94]\n",
      " [101 102 103 104]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fakedata= np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n",
    "fakelabels = np.arange(10) > 4\n",
    "\n",
    "print(fakedata)\n",
    "fakelabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x16888ce50>\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[61, 62, 63, 64]]) torch.Size([1, 4])\n",
      "1 tensor([[41, 42, 43, 44]]) torch.Size([1, 4])\n",
      "2 tensor([[11, 12, 13, 14]]) torch.Size([1, 4])\n",
      "3 tensor([[71, 72, 73, 74]]) torch.Size([1, 4])\n",
      "4 tensor([[21, 22, 23, 24]]) torch.Size([1, 4])\n",
      "5 tensor([[101, 102, 103, 104]]) torch.Size([1, 4])\n",
      "6 tensor([[91, 92, 93, 94]]) torch.Size([1, 4])\n",
      "7 tensor([[51, 52, 53, 54]]) torch.Size([1, 4])\n",
      "8 tensor([[31, 32, 33, 34]]) torch.Size([1, 4])\n",
      "9 tensor([[81, 82, 83, 84]]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fakedataLdr = DataLoader(fakedata,shuffle=True)\n",
    "\n",
    "print(fakedataLdr)\n",
    "print(fakedataLdr.batch_size)\n",
    "\n",
    "\n",
    "for i ,oneSample in enumerate(fakedataLdr):\n",
    "    print(i ,oneSample,oneSample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[61., 62., 63., 64.]]) tensor([1.])\n",
      "tensor([[51., 52., 53., 54.]]) tensor([0.])\n",
      "tensor([[11., 12., 13., 14.]]) tensor([0.])\n",
      "tensor([[81., 82., 83., 84.]]) tensor([1.])\n",
      "tensor([[41., 42., 43., 44.]]) tensor([0.])\n",
      "tensor([[101., 102., 103., 104.]]) tensor([1.])\n",
      "tensor([[71., 72., 73., 74.]]) tensor([1.])\n",
      "tensor([[31., 32., 33., 34.]]) tensor([0.])\n",
      "tensor([[21., 22., 23., 24.]]) tensor([0.])\n",
      "tensor([[91., 92., 93., 94.]]) tensor([1.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakeDataset = torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(fakedata),\n",
    "    torch.Tensor(fakelabels)\n",
    ")\n",
    "\n",
    "fakeDataset.tensors\n",
    "\n",
    "fakedataLdr = DataLoader(fakeDataset,shuffle=True)\n",
    "\n",
    "for dat,lab in fakedataLdr:\n",
    "    print(dat,lab)\n",
    "\n",
    "fakelabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(fakedata,fakelabels,test_size=.2)\n",
    "\n",
    "train_data= torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(train_data),torch.Tensor(train_labels)\n",
    ")\n",
    "\n",
    "test_data= torch.utils.data.TensorDataset(\n",
    "    torch.Tensor(test_data),torch.Tensor(test_labels)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=4)\n",
    "\n",
    "test_loader = DataLoader(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "tensor([[21., 22., 23., 24.],\n",
      "        [51., 52., 53., 54.],\n",
      "        [71., 72., 73., 74.],\n",
      "        [31., 32., 33., 34.]]) tensor([0., 0., 1., 0.])\n",
      "tensor([[101., 102., 103., 104.],\n",
      "        [ 81.,  82.,  83.,  84.],\n",
      "        [ 91.,  92.,  93.,  94.],\n",
      "        [ 41.,  42.,  43.,  44.]]) tensor([1., 1., 1., 0.])\n",
      "Testing data\n",
      "tensor([[61., 62., 63., 64.]]) tensor([1.])\n",
      "tensor([[11., 12., 13., 14.]]) tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Training Data\")\n",
    "\n",
    "for batch ,label in train_loader:\n",
    "    print(batch,label)\n",
    "\n",
    "\n",
    "print('Testing data')\n",
    "\n",
    "for batch,label in test_loader:\n",
    "    print(batch,label)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 真实数据\n",
    "\n",
    "# 分割数据\n",
    "train_data,test_data,train_labels,test_labels = train_test_split(data,labels,train_size=.2)\n",
    "\n",
    "\n",
    "## 转化成 pytorch datasets\n",
    "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
    "test_data = torch.utils.data.TensorDataset(test_data,test_labels)\n",
    "\n",
    "# 最后 转化成 dataloader 对象\n",
    "train_loader = DataLoader(train_data,shuffle=True,batch_size=12)\n",
    "test_loader= DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 4]) torch.Size([12])\n",
      "torch.Size([12, 4]) torch.Size([12])\n",
      "torch.Size([6, 4]) torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# 检查  数据批次的数量\n",
    "for x,y in train_loader:\n",
    "    print(x.shape,y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
